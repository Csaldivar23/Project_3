# Project_3

# Data Engineering Project - Natural Disaster Pipeline

## Project Overview:

The purpose of this project is to create a database with data from Natural Disasters taking place over the last 20 years (2004-2024).

## Project Objective:

The objective of this project is to source data and design a database that can be useful for future purposes. We will be using our ETL skills to transform the originally sourced data to be useful for the context of our database.

The project requirements are as follows:

1. Data must be stored in a SQL or NoSQL database (PostgreSQL, MongoDB, SQLite, etc) and the database must include at least two tables (SQL) or collections (NoSQL).
2. The database must contain at least 100 records.
3. Your project must use ETL workflows to inject data into the database (i.e. the data should not be exactly the same as the original source; it should have been transformed in some way).
4. Your project must include a method for reading data from the database and displaying it for future use, such as Pandas DataFrame or Flask API with JSON output.
5. Your project should include at least one additional library that we did not cover in class related to data engineering. Consider libraries for data streaming, cloud, data pipelines, or data validation.
6. Your documentation should include:

   ● Choice of database with supported reasons why it was selected

   ● ETL workflow with diagrams or ERD
  
8. OPTIONAL: add user-driven interaction, either before or after the ETL process.

## Project Collaborators:

  - Cesar Saldivar
  - Savanna Benn
  - Jack Jefferies
  - Lisa Miller

## Resources:
- EM-DAT - The International Disaster Database - Centre for Research on the Epidemiology of Disasters (CRED)

  Link: https://www.emdat.be/
